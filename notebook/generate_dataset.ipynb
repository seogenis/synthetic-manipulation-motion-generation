{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7e2ff454-b14a-4ef1-986c-9087c003ea53",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "Imitation learning is a type of machine learning where an agent learns to imitate the actions of an expert. In order to train a robust agent, we need a large amount of data. However, manual data collection through human demonstrations is time-consuming and expensive.\n",
    "\n",
    "Isaac Lab Mimic is a feature included in Isaac Lab that allows users to generate new demonstrations by synthesizing trajectories using a small number of human demonstrations. This blueprint will show how to use Isaac Lab Mimic to generate new motion trajectories for a Franka robotic arm and then visually augment using NVIDIA Cosmos to create datasets for imitation learning. The workflow is broken down into two main steps:\n",
    "\n",
    "1. Generate new demonstrations by synthesizing trajectories using a small number of human demonstrations with Isaac Lab Mimic.\n",
    "2. Apply diverse visual transformations using NVIDIA Cosmos to the new demonstrations to create a large and diverse dataset.\n",
    "\n",
    "This notebook will guide you through each step of the workflow.\n",
    "\n",
    "**NOTE: This notebook must be run on the same machine as the Isaac Sim simulator and a display must be connected to the machine.**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5741a94",
   "metadata": {},
   "source": [
    "# Understanding the Blueprint\n",
    "\n",
    "## Motion Trajectory Synthesis\n",
    "Isaac Lab Mimic is a feature set bundled with Isaac Lab (an open source robotic learning framework designed to help train robot policies). The core idea of Mimic is to allow users to synthetically generate a large number of new robot motion trajectories using only a handful of human demonstrations, thus greatly reducing the amount of time and effort required to collect a dataset for imitation learning. \n",
    "\n",
    "Human datasets are annotated with subtask information, which Isaac Lab Mimic uses to construct trajectories for new scene configurations by spatially transforming the original demonstrations.\n",
    "\n",
    "## Visual Augmentation\n",
    "Once generated, the new motion trajectories can be visually augmented using NVIDIA Cosmos to create a diverse dataset that is suitable for training an imitation learning policy. \n",
    "\n",
    "By using multi-staged data generation scheme, we can automatically create a robust dataset for training complex imitation learning policies without the need for large amounts of manual human data, greatly increasing the amount of data available for training and lowering the amount of time required to collect a dataset.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a7239a3",
   "metadata": {},
   "source": [
    "# Generate a New Motion Trajectory"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8f4eee1",
   "metadata": {},
   "source": [
    "\n",
    "## Setup Initial Configuration for Isaac Lab\n",
    "\n",
    "This cell sets up the basic configuration for data generation:\n",
    "\n",
    "1. **How to Modify**:\n",
    "   - Adjust `num_envs` based on your GPU capability\n",
    "   - Set `generation_num_trials` to how many successful trials to execute. Note that some trials may be unsuccessful and so the total number of trials performed may be larger.\n",
    "\n",
    "2. **Tips**:\n",
    "   - Start with 1 trial for testing, increase for training. Increasing trails will increase the time it takes to generate the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "71d91d6e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f716f32d4e7641d2adf11896f44ab5d2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HTML(value='<h3>Set Number of Trials</h3>')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "039769fc83bb41f58a9f1104ad617cb5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HTML(value='<p>How many demonstrations to generate</p>')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e4e6e6a636904dc4a004a08db3913d82",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "BoundedIntText(value=1, description='Number of Trials:', layout=Layout(width='300px'), min=1, style=Descriptioâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from notebook_widgets import create_num_trials_input\n",
    "\n",
    "num_envs = 1\n",
    "num_trials = create_num_trials_input()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddc54d6a",
   "metadata": {},
   "source": [
    "## Spin up the Simulation\n",
    "\n",
    "Run this cell to start the simulation environment. This sets up the necessary components for data generation.\n",
    "\n",
    "**NOTE**: When the simulation is running, a **\"Isaac Sim\" is not responding.\"** pop up may appear. This is expected. Please click the **Wait** option and wait while the process completes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4fa2cf0f-cf3c-4383-a233-216ff1f48c5d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[WARN][AppLauncher]: There are no arguments attached to the ArgumentParser object. If you have your own arguments, please load your own arguments before calling the `AppLauncher.add_app_launcher_args` method. This allows the method to check the validity of the arguments and perform checks for argument names.\n",
      "[INFO][AppLauncher]: Loading experience file: /workspace/isaaclab/apps/isaaclab.python.rendering.kit\n",
      "[Warning] [simulation_app] Interactive python shell detected but ISAAC_JUPYTER_KERNEL was not set. Problems with asyncio may occur\n",
      "[Warning] [simulation_app] Please use Isaac Sim Python 3 kernel instead of the default Python 3 Kernel\n",
      "[Info] [carb] Logging to file: /isaac-sim/kit/logs/Kit/Isaac-Sim/4.5/kit_20250421_045738.log\n",
      "2025-04-21 04:57:38 [0ms] [Warning] [omni.kit.app.plugin] No crash reporter present, dumps uploading isn't available.\n",
      "2025-04-21 04:57:42 [4,008ms] [Warning] [omni.datastore] OmniHub is inaccessible\n",
      "2025-04-21 04:57:43 [4,198ms] [Warning] [carb.windowing-glfw.gamepad] Joystick with unknown remapping detected (will be ignored):  Linux 5.4.62 with aspeed_vhub SMCI HID KM [03000000570500004192000000010000]\n",
      "\n",
      "|---------------------------------------------------------------------------------------------|\n",
      "| Driver Version: 570.124.06    | Graphics API: Vulkan\n",
      "|=============================================================================================|\n",
      "| GPU | Name                             | Active | LDA | GPU Memory | Vendor-ID | LUID       |\n",
      "|     |                                  |        |     |            | Device-ID | UUID       |\n",
      "|     |                                  |        |     |            | Bus-ID    |            |\n",
      "|---------------------------------------------------------------------------------------------|\n",
      "| 0   | NVIDIA H100 NVL                  | Yes: 0 |     | 95830   MB | 10de      | 0          |\n",
      "|     |                                  |        |     |            | 2321      | a2107f06.. |\n",
      "|     |                                  |        |     |            | 17        |            |\n",
      "|---------------------------------------------------------------------------------------------|\n",
      "| 1   | NVIDIA H100 NVL                  |        |     | 95830   MB | 10de      | 0          |\n",
      "|     |                                  |        |     |            | 2321      | 589aa0ee.. |\n",
      "|     |                                  |        |     |            | 63        |            |\n",
      "|=============================================================================================|\n",
      "| OS: 22.04.5 LTS (Jammy Jellyfish) ubuntu, Version: 22.04.5, Kernel: 5.15.0-138-generic\n",
      "| XServer Vendor: The X.Org Foundation, XServer Version: 12101004 (1.21.1.4)\n",
      "| Processor: INTEL(R) XEON(R) GOLD 6548Y+\n",
      "| Cores: 64 | Logical Cores: 128\n",
      "|---------------------------------------------------------------------------------------------|\n",
      "| Total Memory (MB): 1031715 | Free Memory: 1016892\n",
      "| Total Page/Swap (MB): 0 | Free Page/Swap: 0\n",
      "|---------------------------------------------------------------------------------------------|\n",
      "2025-04-21 04:57:45 [6,190ms] [Warning] [gpu.foundation.plugin] ECC is enabled on physical device 0\n",
      "2025-04-21 04:57:47 [8,531ms] [Warning] [omni.log] Source: omni.hydra was already registered.\n",
      "2025-04-21 04:57:49 [10,401ms] [Warning] [omni.isaac.dynamic_control] omni.isaac.dynamic_control is deprecated as of Isaac Sim 4.5. No action is needed from end-users.\n",
      "2025-04-21 04:57:54 [15,996ms] [Warning] [omni.replicator.core.scripts.extension] No material configuration file, adding configuration to material settings directly.\n",
      "2025-04-21 04:57:59 [21,023ms] [Warning] [omni.kit.menu.utils.app_menu] add_menu_items: menu [<MenuItemDescription name:'New'>, <MenuItemDescription name:'Open'>, <MenuItemDescription name:''>, <MenuItemDescription name:'Re-open with New Edit Layer'>, <MenuItemDescription name:''>, <MenuItemDescription name:'Save'>, <MenuItemDescription name:'Save With Options'>, <MenuItemDescription name:'Save As...'>, <MenuItemDescription name:'Save Flattened As...'>, <MenuItemDescription name:''>, <MenuItemDescription name:'Add Reference'>, <MenuItemDescription name:'Add Payload'>, <MenuItemDescription name:''>, <MenuItemDescription name:'Exit'>] cannot change delegate\n",
      "2025-04-21 04:58:09 [30,350ms] [Warning] [omni.usd-abi.plugin] No setting was found for '/rtx-defaults/ambientOcclusion/enabled'\n",
      "2025-04-21 04:58:09 [30,350ms] [Warning] [omni.usd-abi.plugin] No setting was found for '/rtx-defaults/directLighting/sampledLighting/enabled'\n",
      "2025-04-21 04:58:09 [30,350ms] [Warning] [omni.usd-abi.plugin] No setting was found for '/rtx-defaults/indirectDiffuse/enabled'\n",
      "2025-04-21 04:58:09 [30,351ms] [Warning] [omni.usd-abi.plugin] No setting was found for '/rtx-defaults/raytracing/cached/enabled'\n",
      "2025-04-21 04:58:09 [30,351ms] [Warning] [omni.usd-abi.plugin] No setting was found for '/rtx-defaults/reflections/enabled'\n",
      "2025-04-21 04:58:09 [30,351ms] [Warning] [omni.usd-abi.plugin] No setting was found for '/rtx-defaults/sceneDb/ambientLightIntensity'\n",
      "2025-04-21 04:58:09 [30,351ms] [Warning] [omni.usd-abi.plugin] No setting was found for '/rtx-defaults/translucency/enabled'\n",
      "2025-04-21 04:58:09 [30,351ms] [Warning] [omni.usd-abi.plugin] No setting was found for '/rtx-defaults/viewTile/limit'\n",
      "2025-04-21 04:58:09 [30,569ms] [Warning] [rtx.neuraylib.plugin] [IRAY:RENDER]   1.1   IRAY   rend warn : CUDA device 0 (NVIDIA H100 NVL): ECC is enabled, this will reduce rendering performance (it is strongly recommended to disable ECC with iray)\n",
      "2025-04-21 04:58:09 [30,570ms] [Warning] [rtx.neuraylib.plugin] [IRAY:RENDER]   1.1   IRAY   rend warn : CUDA device 1 (NVIDIA H100 NVL): ECC is enabled, this will reduce rendering performance (it is strongly recommended to disable ECC with iray)\n",
      "2025-04-21 04:58:38 [59,155ms] [Warning] [omni.usd-abi.plugin] No setting was found for '/rtx-defaults/directLighting/sampledLighting/samplesPerPixel'\n",
      "2025-04-21 04:58:38 [59,155ms] [Warning] [omni.usd-abi.plugin] No setting was found for '/rtx-defaults/pathtracing/maxSamplesPerLaunch'\n",
      "2025-04-21 04:58:38 [59,155ms] [Warning] [omni.usd-abi.plugin] No setting was found for '/rtx-defaults-transient/meshlights/forceDisable'\n",
      "2025-04-21 04:58:38 [59,220ms] [Warning] [omni.usd-abi.plugin] No setting was found for '/rtx-defaults/post/dlss/execMode'\n",
      "2025-04-21 04:58:42 [63,800ms] [Warning] [rtx.postprocessing.plugin] DLSS-RR is not supported in the current build due to some known bugs with this GPU: NVIDIA H100 NVL.Note that RTX Real-Time raytracing mode will not be able to denoise the output correctly.\n",
      "2025-04-21 04:58:45 [66,316ms] [Warning] [isaaclab.envs.manager_based_env] Seed not set for the environment. The environment creation may not be deterministic.\n",
      "2025-04-21 04:58:49 [70,105ms] [Warning] [isaaclab.actuators.actuator_pd] The <ImplicitActuatorCfg> object has a value for 'effort_limit'. This parameter will be removed in the future. To set the effort limit, please use 'effort_limit_sim' instead.\n",
      "2025-04-21 04:58:49 [70,105ms] [Warning] [isaaclab.actuators.actuator_pd] The <ImplicitActuatorCfg> object has a value for 'velocity_limit'. Previously, although this value was specified, it was not getting used by implicit actuators. Since this parameter affects the simulation behavior, we continue to not use it. This parameter will be removed in the future. To set the velocity limit, please use 'velocity_limit_sim' instead.\n",
      "2025-04-21 04:58:49 [70,111ms] [Warning] [isaaclab.actuators.actuator_pd] The <ImplicitActuatorCfg> object has a value for 'effort_limit'. This parameter will be removed in the future. To set the effort limit, please use 'effort_limit_sim' instead.\n",
      "2025-04-21 04:58:49 [70,111ms] [Warning] [isaaclab.actuators.actuator_pd] The <ImplicitActuatorCfg> object has a value for 'velocity_limit'. Previously, although this value was specified, it was not getting used by implicit actuators. Since this parameter affects the simulation behavior, we continue to not use it. This parameter will be removed in the future. To set the velocity limit, please use 'velocity_limit_sim' instead.\n",
      "2025-04-21 04:58:49 [70,112ms] [Warning] [isaaclab.actuators.actuator_pd] The <ImplicitActuatorCfg> object has a value for 'effort_limit'. This parameter will be removed in the future. To set the effort limit, please use 'effort_limit_sim' instead.\n",
      "2025-04-21 04:58:49 [70,112ms] [Warning] [isaaclab.actuators.actuator_pd] The <ImplicitActuatorCfg> object has a value for 'velocity_limit'. Previously, although this value was specified, it was not getting used by implicit actuators. [INFO]: Parsing configuration from: <class 'isaaclab_mimic.envs.franka_stack_ik_rel_blueprint_mimic_env_cfg.FrankaCubeStackIKRelBlueprintMimicEnvCfg'>\n",
      "[INFO]: Base environment:\n",
      "\tEnvironment device    : cuda:0\n",
      "\tEnvironment seed      : None\n",
      "\tPhysics step-size     : 0.01\n",
      "\tRendering step-size   : 0.05\n",
      "\tEnvironment step-size : 0.05\n",
      "[INFO]: Time taken for scene creation : 1.262695 seconds\n",
      "[INFO]: Scene manager:  <class InteractiveScene>\n",
      "\tNumber of environments: 1\n",
      "\tEnvironment spacing   : 2.5\n",
      "\tSource prim name      : /World/envs/env_0\n",
      "\tGlobal prim paths     : []\n",
      "\tReplicate physics     : False\n",
      "[INFO] Event Manager:  <EventManager> contains 2 active terms.\n",
      "+---------------------------------------+\n",
      "| Active Event Terms in Mode: 'startup' |\n",
      "+---------+-----------------------------+\n",
      "|  Index  | Name                        |\n",
      "+---------+-----------------------------+\n",
      "|    0    | init_franka_arm_pose        |\n",
      "+---------+-----------------------------+\n",
      "+--------------------------------------+\n",
      "| Active Event Terms in Mode: 'reset'  |\n",
      "+-------+------------------------------+\n",
      "| Index | Name                         |\n",
      "+-------+------------------------------+\n",
      "|   0   | randomize_franka_joint_state |\n",
      "|   1   | randomize_cube_positions     |\n",
      "+-------+------------------------------+\n",
      "\n",
      "[INFO]: Starting the simulation. This may take a few seconds. Please wait...\n",
      "[INFO]: Time taken for simulation start : 21.471521 seconds\n",
      "[INFO] Command Manager:  <CommandManager> contains 0 active terms.\n",
      "+------------------------+\n",
      "|  Active Command Terms  |\n",
      "+--------+-------+-------+\n",
      "| Index  | Name  |  Type |\n",
      "+--------+-------+-------+\n",
      "+--------+-------+-------+\n",
      "\n",
      "[INFO] Recorder Manager:  <RecorderManager> contains 4 active terms.\n",
      "+--------------------------------------------------+\n",
      "|              Active Recorder Terms               |\n",
      "+-------+------------------------------------------+\n",
      "| Index | Name                                     |\n",
      "+-------+------------------------------------------+\n",
      "|   0   | record_initial_state                     |\n",
      "|   1   | record_post_step_states                  |\n",
      "|   2   | record_pre_step_actions                  |\n",
      "|   3   | record_pre_step_flat_policy_observations |\n",
      "+-------+------------------------------------------+\n",
      "\n",
      "[INFO] Action Manager:  <ActionManager> contains 2 active terms.\n",
      "+------------------------------------+\n",
      "|   Active Action Terms (shape: 7)   |\n",
      "+-------+----------------+-----------+\n",
      "| Index | Name           | Dimension |\n",
      "+-------+----------------+-----------+\n",
      "|   0   | arm_action     |         6 |\n",
      "|   1   | gripper_action |         1 |\n",
      "+-------+----------------+-----------+\n",
      "\n",
      "[INFO] Observation Manager: <ObservationManager> contains 3 groups.\n",
      "+---------------------------------------------+\n",
      "| Active Observation Terms in Group: 'policy' |\n",
      "+---------+-------------------------+---------+\n",
      "|  Index  | Name                    |  Shape  |\n",
      "+---------+-------------------------+---------+\n",
      "|    0    | actions                 |   (7,)  |\n",
      "|    1    | joint_pos               |   (9,)  |\n",
      "|    2    | joint_vel               |   (9,)  |\n",
      "|    3    | object                  |  (39,)  |\n",
      "|    4    | cube_positions          |   (9,)  |\n",
      "|    5    | cube_orientations       |  (12,)  |\n",
      "|    6    | eef_pos                 |   (3,)  |\n",
      "|    7    | eef_quat                |   (4,)  |\n",
      "|    8    | gripper_pos             |   (2,)  |\n",
      "+---------+-------------------------+---------+\n",
      "+------------------------------------------------------+\n",
      "|   Active Observation Terms in Group: 'rgb_camera'    |\n",
      "+-------+-----------------------------+----------------+\n",
      "| Index | Name                        |     Shape      |\n",
      "+-------+-----------------------------+----------------+\n",
      "|   0   | table_cam_normals           | (704, 1280, 3) |\n",
      "|   1   | table_cam_segmentation      | (704, 1280, 4) |\n",
      "|   2   | table_high_cam_normals      | (704, 1280, 3) |\n",
      "|   3   | table_high_cam_segmentation | (704, 1280, 4) |\n",
      "+-------+-----------------------------+----------------+\n",
      "+----------------------------------------------+\n",
      "| Active Observation Terms in Group: 'subtask_terms' |\n",
      "+-------------+------------------+-------------+\n",
      "|    Index    | Name             |    Shape    |\n",
      "+-------------+------------------+-------------+\n",
      "|      0      | grasp_1          |      ()     |\n",
      "|      1      | stack_1          |      ()     |\n",
      "|      2      | grasp_2          |      ()     |\n",
      "+-------------+------------------+-------------+\n",
      "\n",
      "[INFO] Termination Manager:  <TerminationManager> contains 0 active terms.\n",
      "+----------------------------+\n",
      "|  Active Termination Terms  |\n",
      "+--------+-------+-----------+\n",
      "| Index  | Name  |  Time Out |\n",
      "+--------+-------+-----------+\n",
      "+--------+-------+-----------+\n",
      "\n",
      "[INFO] Reward Manager:  <RewardManager> contains 0 active terms.\n",
      "+-----------------------+\n",
      "|  Active Reward Terms  |\n",
      "+-------+------+--------+\n",
      "| Index | Name | Weight |\n",
      "+-------+------+--------+\n",
      "+-------+------+--------+\n",
      "\n",
      "[INFO] Curriculum Manager:  <CurriculumManager> contains 0 active terms.\n",
      "+----------------------+\n",
      "| Active Curriculum Terms |\n",
      "+-----------+----------+\n",
      "|   Index   | Name     |\n",
      "+-----------+----------+\n",
      "+-----------+----------+\n",
      "\n",
      "Creating window for environment.\n",
      "[INFO]: Completed setting up the environment...\n",
      "Encoding 120 frames to _isaaclab_out/shaded_segmentation_table_cam_trial_0_tile_0.mp4...\n",
      "Video successfully encoded to _isaaclab_out/shaded_segmentation_table_cam_trial_0_tile_0.mp4\n",
      "Updated 'pose_range.y' to (-0.09999999999999998, 0.10000000000000003).\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import nest_asyncio\n",
    "nest_asyncio.apply()\n",
    "\n",
    "from argparse import ArgumentParser, Namespace\n",
    "from isaaclab.app import AppLauncher\n",
    "\n",
    "parser = ArgumentParser()\n",
    "AppLauncher.add_app_launcher_args(parser)\n",
    "args_cli = parser.parse_args([])\n",
    "args_cli.enable_cameras = True\n",
    "args_cli.kit_args = \"--enable omni.videoencoding\"\n",
    "\n",
    "config = {\n",
    "    \"task\": \"Isaac-Stack-Cube-Franka-IK-Rel-Blueprint-Mimic-v0\",  \n",
    "    \"num_envs\": num_envs,                                       \n",
    "    \"generation_num_trials\": num_trials.value,                         \n",
    "    \"input_file\": \"datasets/annotated_dataset.hdf5\",     \n",
    "    \"output_file\": \"datasets/generated_dataset.hdf5\", \n",
    "    \"pause_subtask\": False,\n",
    "    \"enable\": \"omni.kit.renderer.capture\",\n",
    "}\n",
    "\n",
    "# Update the default configuration\n",
    "args_dict = vars(args_cli)\n",
    "args_dict.update(config)\n",
    "args_cli = Namespace(**args_dict)\n",
    "\n",
    "# Now launch the simulator with the final configuration\n",
    "app_launcher = AppLauncher(args_cli)\n",
    "simulation_app = app_launcher.app\n",
    "\n",
    "import asyncio\n",
    "import gymnasium as gym\n",
    "import numpy as np\n",
    "import random\n",
    "import torch\n",
    "\n",
    "import isaaclab_mimic.envs  # noqa: F401\n",
    "from isaaclab_mimic.datagen.generation import env_loop, setup_env_config, setup_async_generation\n",
    "from isaaclab_mimic.datagen.utils import get_env_name_from_dataset, setup_output_paths, interactive_update_randomizable_params, reset_env\n",
    "from isaaclab.managers import ObservationTermCfg as ObsTerm\n",
    "from notebook_utils import ISAACLAB_OUTPUT_DIR\n",
    "\n",
    "import isaaclab_tasks  # noqa: F401\n",
    "num_envs = args_cli.num_envs\n",
    "\n",
    "# Setup output paths and get env name\n",
    "output_dir, output_file_name = setup_output_paths(args_cli.output_file)\n",
    "env_name = args_cli.task or get_env_name_from_dataset(args_cli.input_file)\n",
    "\n",
    "# Configure environment\n",
    "env_cfg, success_term = setup_env_config(\n",
    "    env_name=env_name,\n",
    "    output_dir=output_dir,\n",
    "    output_file_name=output_file_name,\n",
    "    num_envs=num_envs,\n",
    "    device=args_cli.device,\n",
    "    generation_num_trials=args_cli.generation_num_trials,\n",
    ")\n",
    "# Set observation output directory\n",
    "for obs in vars(env_cfg.observations.rgb_camera).values():\n",
    "    if not isinstance(obs, ObsTerm):\n",
    "        continue\n",
    "    obs.params[\"image_path\"] = os.path.join(ISAACLAB_OUTPUT_DIR, obs.params[\"image_path\"])\n",
    "env_cfg.observations\n",
    "\n",
    "\n",
    "# create environment\n",
    "env = gym.make(env_name, cfg=env_cfg).unwrapped\n",
    "\n",
    "# set seed for generation\n",
    "random.seed(env.cfg.datagen_config.seed)\n",
    "np.random.seed(env.cfg.datagen_config.seed)\n",
    "torch.manual_seed(env.cfg.datagen_config.seed)\n",
    "\n",
    "# reset before starting\n",
    "reset_env(env, 100)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74fd57b1",
   "metadata": {},
   "source": [
    "## Interactive Parameter Updates\n",
    "\n",
    "To get diversity in the generated motion trajectories, the scene configuration is randomized for each trial. This section provides interactive sliders and controls to adjust various environment parameters in real-time:\n",
    "\n",
    "1. **What You'll See**:\n",
    "   - Sliders for numerical values\n",
    "   - Range inputs for min/max settings\n",
    "   - Current value displays\n",
    "   - Parameter names and allowed ranges\n",
    "\n",
    "2. **How to Use**:\n",
    "   - Move the sliders to adjust values\n",
    "   - Watch the environment update in real-time\n",
    "\n",
    "3. **Available Parameters**:\n",
    "   - **Franka Joint State Randomization**:\n",
    "     - **mean (0.0 - 0.5)**: Controls the average joint angle offset (in radians)\n",
    "     - **std (0.0 - 0.1)**: Controls the spread of randomization around the mean\n",
    "\n",
    "   - **Cube Position Randomization**:\n",
    "     - **pose_range.x (0.3 - 0.9)**: Controls cube placement along the x-axis (in meters)\n",
    "     - **pose_range.y (-0.3 - 0.3)**: Controls cube placement along the y-axis (in meters)\n",
    "     - **min_separation (0.0 - 0.5)**: Minimum allowed distance between cubes (in meters)\n",
    "     \n",
    "     **Note:** If the system cannot place cubes with the specified minimum separation after several attempts (due to space constraints), it will accept the last generated positions even if they don't meet the separation requirement. This prevents the system from getting stuck in an impossible configuration.\n",
    "\n",
    "\n",
    "4. **Tips**:\n",
    "   - Start with small adjustments to understand their effects\n",
    "\n",
    "Note: These adjustments will affect how new demonstrations are generated, so take time to experiment with different settings to achieve desired behavior."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ec27b67f-d051-45e5-878f-2f6e1e6822f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Updating parameters for event: randomize_joint_by_gaussian_offset'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "decea48d75384735ad05fa733e698218",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(Label(value='randomize_franka_joint_state.mean', layout=Layout(width='auto')), FloatSlider(valuâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3619e77d49b742049974cf0cf94c67d6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HTML(value='<p style=\"color:gray\">Allowed range: (0.0, 0.5)</p>')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c2c1eddc88624e679cc3462edace4c7b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(Label(value='randomize_franka_joint_state.std', layout=Layout(width='auto')), FloatSlider(valueâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "287224b0db1543a79063768f396a0599",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HTML(value='<p style=\"color:gray\">Allowed range: (0.0, 0.1)</p>')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'Updating parameters for event: randomize_object_pose'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9931a5f8b7cf4f528944b93200c59a8b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(Label(value='randomize_cube_positions.pose_range.x', layout=Layout(width='auto')), FloatRangeSlâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "442e6ff11a0b4211866b77ac5bf30a24",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HTML(value='<p style=\"color:gray\">Allowed range: (0.3, 0.9)</p>')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "63af0a38af8c4d8da317990e5943b9fb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(Label(value='randomize_cube_positions.pose_range.y', layout=Layout(width='auto')), FloatRangeSlâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a064f6744de0482293c126903f5fb6b4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HTML(value='<p style=\"color:gray\">Allowed range: (-0.3, 0.3)</p>')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cee95fad2fcb4672b118aaea96e1cd0d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(Label(value='randomize_cube_positions.min_separation', layout=Layout(width='auto')), FloatSlideâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "29d7675d641c41279fff50050a26f245",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HTML(value='<p style=\"color:gray\">Allowed range: (0.0, 0.5)</p>')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "randomizable_params = {\n",
    "    \"randomize_franka_joint_state\": {\n",
    "        \"mean\": (0.0, 0.5, 0.01),\n",
    "        \"std\": (0.0, 0.1, 0.01),\n",
    "    },\n",
    "    \"randomize_cube_positions\": {\n",
    "        \"pose_range\": {\n",
    "                \"x\": (0.3, 0.9, 0.01),\n",
    "                \"y\": (-0.3, 0.3, 0.01),\n",
    "            },\n",
    "        \"min_separation\": (0.0, 0.5, 0.01),\n",
    "    }\n",
    "}\n",
    "\n",
    "for i in range(len(env.unwrapped.event_manager._mode_term_cfgs[\"reset\"])):\n",
    "    event_term = env.unwrapped.event_manager._mode_term_cfgs[\"reset\"][i]\n",
    "    name = env.unwrapped.event_manager.active_terms[\"reset\"][i]\n",
    "    display(f\"Updating parameters for event: {event_term.func.__name__}\")\n",
    "    interactive_update_randomizable_params(event_term, name, randomizable_params[name], env=env)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03d35f42",
   "metadata": {},
   "source": [
    "## Data Generation\n",
    "\n",
    "Run this cell to start generating demonstrations using the parameters you've configured. The process will:\n",
    "- Generate the specified number of demonstrations\n",
    "- Save successful demonstrations to your output file\n",
    "- Show progress as demonstrations are generated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "035cd632-b2a5-4e23-8ad4-3df7e32a2512",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Loaded 10 to datagen info pool"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "**************************************************"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "have 1 successes out of 1 trials so far"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "have 0 failures out of 1 trials so far"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "**************************************************"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Reached 1 successes/attempts. Exiting."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Tasks were properly cancelled during cleanup."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import sys\n",
    "from IPython.display import display, Pretty\n",
    "\n",
    "# Create a new output capture\n",
    "class OutputCapture:\n",
    "    def __init__(self):\n",
    "        self._buffer = \"\"\n",
    "    \n",
    "    def write(self, text):\n",
    "        if text.strip():  # Only process non-empty strings\n",
    "            display(Pretty(text.rstrip()))\n",
    "    \n",
    "    def flush(self):\n",
    "        if self._buffer:\n",
    "            display(Pretty(self._buffer))\n",
    "            self._buffer = \"\"\n",
    "\n",
    "# Move stdout redirection before setup_async_generation\n",
    "old_stdout = sys.stdout\n",
    "sys.stdout = OutputCapture()\n",
    "\n",
    "try:\n",
    "    # Setup and run async data generation\n",
    "    async_components = setup_async_generation(\n",
    "        env=env,\n",
    "        num_envs=args_cli.num_envs,\n",
    "        input_file=args_cli.input_file,\n",
    "        success_term=success_term,\n",
    "        pause_subtask=args_cli.pause_subtask\n",
    "    )\n",
    "\n",
    "    future = asyncio.ensure_future(asyncio.gather(*async_components['tasks']))\n",
    "    env_loop(env, async_components['action_queue'], \n",
    "            async_components['info_pool'], async_components['event_loop'])\n",
    "except asyncio.CancelledError:\n",
    "    display(Pretty(\"Tasks were cancelled.\"))\n",
    "except AttributeError as e:\n",
    "    if \"'FrankaCubeStackIKRelMimicEnv' object has no attribute 'scene'\" in str(e):\n",
    "        display(Pretty(\"Environment was closed during execution. This is expected behavior.\"))\n",
    "except Exception as e:\n",
    "    display(Pretty(f\"Error occurred: {str(e)}\"))\n",
    "finally:\n",
    "    # Restore original stdout first\n",
    "    sys.stdout = old_stdout\n",
    "    \n",
    "    # Cancel the future and ignore any AttributeErrors from pending tasks\n",
    "    if 'future' in locals():\n",
    "        future.cancel()\n",
    "        try:\n",
    "            async_components['event_loop'].run_until_complete(future)\n",
    "        except (asyncio.CancelledError, AttributeError) as e:\n",
    "            if isinstance(e, AttributeError) and \"'FrankaCubeStackIKRelMimicEnv' object has no attribute 'scene'\" in str(e):\n",
    "                display(Pretty(\"Environment was closed during execution. This is expected behavior!\"))\n",
    "            elif isinstance(e, asyncio.CancelledError):\n",
    "                display(Pretty(\"Tasks were properly cancelled during cleanup.\"))\n",
    "            else:\n",
    "                display(Pretty(f\"Unexpected cleanup error: {str(e)}\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fcd54f9-b002-4028-9699-bd85827b98e3",
   "metadata": {},
   "source": [
    "# Cosmos\n",
    "\n",
    "Now that a new motion trajectory has been generated, we will apply visual transformations to the data using Cosmos to create a realistic demo that is suitable for training an imitation learning policy.\n",
    "\n",
    "## Video Preprocessing\n",
    "In this first step, we will process the generated motion trajectory into a video that can be used as an input for the Cosmos model.\n",
    "The normals of the scene are used to apply shading to the semantic segmentation which produces an input that works very well with the Cosmos model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7c599698-a590-4eca-a53b-dba6011be42e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "088cd800b6014c3e89b2378ab7a1b1f9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HTML(value='<h3>1. Select Camera</h3>')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5f7c1140230f4381b33825188dd5c1c1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Dropdown(description='Source Camera:', layout=Layout(width='auto'), options=('table_cam', 'table_high_cam'), sâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from notebook_widgets import create_camera_input\n",
    "from notebook_utils import ISAACLAB_OUTPUT_DIR\n",
    "\n",
    "VIDEO_LENGTH = 120   # Suggested length is between 120 and 200\n",
    "camera_selection = create_camera_input(ISAACLAB_OUTPUT_DIR)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3d446c26-d7e3-4515-9818-c8bf4f93da13",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'_isaaclab_out/shaded_segmentation_table_cam_trial_0_tile_0.mp4'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<video src=\"_isaaclab_out/shaded_segmentation_table_cam_trial_0_tile_0.mp4\" controls  width=\"1000\" >\n",
       "      Your browser does not support the <code>video</code> element.\n",
       "    </video>"
      ],
      "text/plain": [
       "<IPython.core.display.Video object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "from IPython.display import Video\n",
    "from notebook_utils import encode_video, ISAACLAB_OUTPUT_DIR, get_env_trial_frames\n",
    "\n",
    "env_trial_frames = get_env_trial_frames(ISAACLAB_OUTPUT_DIR, camera_selection.value, 10)\n",
    "camera = camera_selection.value\n",
    "for env_num, trial_nums in env_trial_frames.items():\n",
    "    for trial_num, (start_frame, end_frame) in trial_nums.items():\n",
    "        trial_length = end_frame - start_frame + 1\n",
    "        if trial_length < VIDEO_LENGTH:\n",
    "            print(f\"\\nSkipping Trial {trial_num}: Too short ({trial_length} frames)\")\n",
    "            continue\n",
    "            \n",
    "        video_start = max(start_frame, end_frame - VIDEO_LENGTH + 1)\n",
    "        \n",
    "        # Generate video filename with trial number\n",
    "        video_filepath = os.path.join(ISAACLAB_OUTPUT_DIR, f\"shaded_segmentation_{camera}_trial_{trial_num}_tile_{env_num}.mp4\")\n",
    "            \n",
    "        try:\n",
    "            encode_video(ISAACLAB_OUTPUT_DIR, video_start, VIDEO_LENGTH, \n",
    "                        camera, video_filepath, env_num, trial_num)\n",
    "            display(video_filepath)\n",
    "            display(Video(video_filepath, width=1000))\n",
    "        except ValueError as e:\n",
    "            print(f\"Error processing trial {trial_num}: {str(e)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3caa2e8a-0748-4201-b6e2-6582455bea85",
   "metadata": {},
   "source": [
    "## Deploying Cosmos\n",
    "Deploy Cosmos on your provider of choice, or to your own local resources: [Cosmos Transfer1](https://huggingface.co/nvidia/Cosmos-Transfer1-7B). \n",
    "Click on the `Code` link on the Cosmos Transfer page and follow the installation steps outlined in the README. You can find detailed setup instructions in under `examples/inference_multi_control_manual_input.md`.\n",
    "\n",
    "> ### Adding a Web API to Cosmos Transfer1\n",
    "> To simplify testing, copy the file `notebook/app.py` into the Cosmos root directory, and run it with `python app.py`. This will expose endpoints which we'll use to communicate between the notebook and the cosmos model. The script exposes endpoints at port `5000` by default."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2cdf11a7-4375-478c-a066-f109ce847601",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d854c5d881d94a57ac5a819892306bf3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Text(value='', description='Cosmos URL:', layout=Layout(width='1000px'), placeholder='cosmos/url:port', style=â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import ipywidgets as widgets\n",
    "url_widget = widgets.Text(value=\"\", placeholder=\"cosmos/url:port\", description=\"Cosmos URL:\", style={'description_width': 'initial'}, layout={\"width\": \"1000px\"})\n",
    "display(url_widget)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47fe33b4-3943-4716-92cd-e3cbc642ff6d",
   "metadata": {},
   "source": [
    "### Using the Cosmos Model\n",
    "\n",
    "The Cosmos model has several available parameters which alter the output in various ways:\n",
    "- `prompt`: Text prompt for the video generation.\n",
    "- `seed`: Seed for the random number generator. `int [0 - 2147483648]`\n",
    "- `control_weight`: Controls how strongly the control input should affect the output. The stronger the effect, the more adherance to the control input, but the less the model generation freedom. `float [0 - 1.0]`\n",
    "- `sigma_max`: A float value representing the maximum sigma. Lower values result in less change from the original input while a larger values allows for more change but may diverge more from the input scene. `float [0 - 80.0]`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fd47b996-132e-416a-a94d-ba0548bfdcab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4f80043768984102b9ef4c1a55181232",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HTML(value='<h3>Prompt Generator</h3>')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8310b77da7724da994a5852c65b19ea5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(Dropdown(description='Cube Description:', layout=Layout(margin='0 20px 0 0', width='200'), optiâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7278c0a637a3453a9e18f9dc3d741c64",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HTML(value='<h4>Prompt</h4>')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b64e21cc431e4fc3b39d1ea6fb10a9e1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HTML(value='The scene depicts a robotic arm performing a precise block-stacking operation with glass\\ncubes inâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9f1ecb48b83e494da09f53f919cc348a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HTML(value='<h3>Cosmos Parameters</h3>')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7990a936fa2a4c11b58514d1091ba7b1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Dropdown(description='Input Video:', layout=Layout(width='500px'), options=('shaded_segmentation_table_cam_triâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "26fb429b42a9424c9dbc49407e566597",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntText(value=42, description='Seed:', layout=Layout(margin='0 20px 0 0', width='150px'), styleâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from notebook_widgets import create_variable_dropdowns, create_cosmos_params\n",
    "from notebook_utils import ISAACLAB_OUTPUT_DIR, COSMOS_OUTPUT_DIR\n",
    "\n",
    "prompt_manager = create_variable_dropdowns(\"stacking_prompt.toml\")\n",
    "cosmos_params = create_cosmos_params(ISAACLAB_OUTPUT_DIR)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "837ad2d0-7fc3-45ad-88ed-748e34b6eafd",
   "metadata": {},
   "source": [
    "## Generate with Cosmos\n",
    "---\n",
    "> **NOTE:** Generation generally takes around 5 to 10 minutes on a single H100 GPU depending on the video length.\n",
    "\n",
    "---\n",
    "\n",
    "> **Tips:**\n",
    "> - To increase prompt adherence, try increasing the `Sigma Max` value\n",
    "> - To reduce divergence from the input scene, try increasing the `Control Weight` and/or increasing `Canny Strength`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ff80ae7d-2698-41be-8812-fc1597c208f7",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Enter URL to proceed.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 13\u001b[0m\n\u001b[1;32m     10\u001b[0m params[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mprompt\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m prompt_manager\u001b[38;5;241m.\u001b[39mprompt\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m url_widget\u001b[38;5;241m.\u001b[39mvalue:\n\u001b[0;32m---> 13\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEnter URL to proceed.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     15\u001b[0m response \u001b[38;5;241m=\u001b[39m process_video(\n\u001b[1;32m     16\u001b[0m     url\u001b[38;5;241m=\u001b[39murl_widget\u001b[38;5;241m.\u001b[39mvalue,\n\u001b[1;32m     17\u001b[0m     video_path\u001b[38;5;241m=\u001b[39mvideo_filepath,\n\u001b[1;32m     18\u001b[0m     output_path\u001b[38;5;241m=\u001b[39moutput_path,\n\u001b[1;32m     19\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams,\n\u001b[1;32m     20\u001b[0m )\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m response \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mValueError\u001b[0m: Enter URL to proceed."
     ]
    }
   ],
   "source": [
    "import os\n",
    "from cosmos_request import process_video\n",
    "from notebook_utils import ISAACLAB_OUTPUT_DIR\n",
    "from notebook_widgets import create_download_link\n",
    "from IPython.display import Video, clear_output\n",
    "\n",
    "params = {k: w.value for k, w in cosmos_params.items()}\n",
    "video_filepath = os.path.join(ISAACLAB_OUTPUT_DIR, params.pop(\"input_video\"))\n",
    "output_path = f\"{COSMOS_OUTPUT_DIR}/cosmos_{params['seed']}.mp4\"\n",
    "params[\"prompt\"] = prompt_manager.prompt\n",
    "\n",
    "if not url_widget.value:\n",
    "    raise ValueError(\"Enter URL to proceed.\")\n",
    "\n",
    "response = process_video(\n",
    "    url=url_widget.value,\n",
    "    video_path=video_filepath,\n",
    "    output_path=output_path,\n",
    "    **params,\n",
    ")\n",
    "if response is None:\n",
    "    display(\"An error occurred processing the request\")\n",
    "elif response.status_code == 200:\n",
    "    clear_output(wait=True)\n",
    "    display(Video(output_path))\n",
    "    display(create_download_link(output_path, link_text=f\"Download Video: {output_path}\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daa860c4",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "784bd2fe-e628-4e7d-bcbd-c73bafcf4648",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
